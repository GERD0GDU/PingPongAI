# Neden Bu Mimari?

Bu projede kullanÄ±lan mimari tesadÃ¼fi deÄŸildir.

Ama aynÄ± zamanda:

- akademik bir referans mimari deÄŸildir
- endÃ¼striyel Ã¶lÃ§ekte optimize edilmemiÅŸtir
- "en doÄŸru yol" iddiasÄ± taÅŸÄ±maz

Bu mimari, **Ã¶ÄŸrenmeyi gÃ¶rÃ¼nÃ¼r kÄ±lmak** iÃ§in seÃ§ilmiÅŸtir.

## Ä°lham: Demis Hassabis YaklaÅŸÄ±mÄ±

Bu projenin dÃ¼ÅŸÃ¼nsel arka planÄ±nda, DeepMind kurucularÄ±ndan Demis Hassabis'in ÅŸu fikri vardÄ±r:

> KarmaÅŸÄ±k problemleri Ã§Ã¶zmek iÃ§in\
karmaÅŸÄ±k kurallar yazmak yerine\
Ã¶ÄŸrenebilen sistemler kurmak

Bu yaklaÅŸÄ±mda:

- sistem ne yapacaÄŸÄ±nÄ± bilmez
- kurallar minimumda tutulur
- Ã¶ÄŸrenme sÃ¼reci merkeze alÄ±nÄ±r

Ping-pong oyunu bu yÃ¼zden seÃ§ilmiÅŸtir.

## Neden Self-Play?

Self-play ÅŸu anlama gelir:

> Sistemin kendi kendine oynamasÄ± - Ã¶ÄŸrenmesi

Bu sayede:

- dÄ±ÅŸarÄ±dan "iyi davranÄ±ÅŸ" tanÄ±mÄ± verilmez
- insan stratejileri kopyalanmaz
- tek referans baÅŸarÄ± - baÅŸarÄ±sÄ±zlÄ±ktÄ±r

AI, baÅŸka bir AI ile oynarken:

- hatalarÄ±nÄ± tekrar tekrar gÃ¶rÃ¼r
- kendi sÄ±nÄ±rlarÄ±nÄ± zorlar
- beklenmedik ama iÅŸe yarayan davranÄ±ÅŸlar geliÅŸtirir

Bu, Ã¶ÄŸrenmenin en saf halidir.

## Neden ModÃ¼ler YapÄ±?

Projede ÅŸu parÃ§alar bilinÃ§li olarak ayrÄ±lmÄ±ÅŸtÄ±r:

- oyun motoru
- fizik hesaplarÄ±
- AI ajanÄ±
- Ã¶ÄŸrenme mekanizmasÄ±
- gÃ¶rselleÅŸtirme katmanÄ±

Sebebi ÅŸudur:

> Ã–ÄŸrenme kodu ile oyun kodu birbirine karÄ±ÅŸÄ±rsa\
neyin neden olduÄŸunu anlayamazsÄ±n

ModÃ¼ler yapÄ± sayesinde:

- AI olmadan oyun Ã§alÄ±ÅŸÄ±r
- oyun olmadan AI test edilebilir
- her parÃ§a tek baÅŸÄ±na anlaÅŸÄ±labilir

Bu proje; bir "Ã¼rÃ¼n" deÄŸil bir **inceleme laboratuvarÄ±dÄ±r**.

## Neden HazÄ±r KÃ¼tÃ¼phane Yok?

Bu projede:

- TensorFlow yok
- PyTorch yok
- hazÄ±r RL framework yok

Ã‡Ã¼nkÃ¼ amaÃ§:

- sonucu almak deÄŸil
- sÃ¼reci anlamak

HazÄ±r kÃ¼tÃ¼phaneler:

- Ã§ok gÃ¼Ã§lÃ¼dÃ¼r
- ama Ã¶ÄŸrenme sÃ¼recini gizler

Burada ise her aÄŸÄ±rlÄ±k deÄŸiÅŸimi bilinÃ§li olarak gÃ¶rÃ¼nÃ¼r kÄ±lÄ±nÄ±r.

## Mimari Ne SaÄŸlar?

Bu mimari sayesinde:

- AI'nin nasÄ±l karar verdiÄŸi izlenebilir
- hatalarÄ±n kaynaÄŸÄ± anlaÅŸÄ±labilir
- "burada neden bÃ¶yle davrandÄ±?" sorusu sorulabilir

Bu sorularÄ±n sorulabildiÄŸi bir sistem:

> Ã¶ÄŸrenmeye gerÃ§ekten aÃ§Ä±ktÄ±r

## Bu Mimari Ne Yapmaz?

Bu mimari:

- ğŸ”¥ insan gibi dÃ¼ÅŸÃ¼nmez
- ğŸ§  sezgi Ã¼retmez
- âœ¨ sihir yapmaz

YaptÄ±ÄŸÄ± tek ÅŸey ÅŸudur:

> Deneyim - geri bildirim - ayarlama

Ama bu Ã¼Ã§lÃ¼ bir araya geldiÄŸinde Ã§ok gÃ¼Ã§lÃ¼ bir yapÄ± ortaya Ã§Ä±kar.

## SonuÃ§

Bu mimari:

- basit gÃ¶rÃ¼nÃ¼r
- yavaÅŸ Ã¶ÄŸrenir
- mÃ¼tevazÄ±dÄ±r

Ama tam da bu yÃ¼zden:

- Ã¶ÄŸreticidir
- ÅŸeffaftÄ±r
- gÃ¼venilirdir

PingPongAI'nin mimarisi, AI'yi yÃ¼celtmek iÃ§in deÄŸil **anlaÅŸÄ±lÄ±r kÄ±lmak iÃ§in** vardÄ±r.

## AyrÄ±ca BakÄ±nÄ±z

- [Ana Sayfa](../../README.md)
- [AI nedir, ne deÄŸildir, kodla iliÅŸkisi](00-WhatIsAI.md)
- [Ã–ÄŸrenme kavramÄ±, supervised / unsupervised / reinforcement](./01-WhatIsLearning.md)
- [Yapay nÃ¶ron, girdi/aÄŸÄ±rlÄ±k/bias, basit Ã¶rnek](./02-Neuron.md)
- [Mini neural network, hidden layer, ileri beslemeli aÄŸ](./03-NeuralNetwork.md)
- [Ã–dÃ¼l ve ceza, self-play, temel RL mantÄ±ÄŸÄ±](./04-ReinforcementLearning.md)
- *Hassabis yaklaÅŸÄ±mÄ±, self-play, modÃ¼ler mimari*
